{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945e3210-eb58-443e-a43a-16a2ad218ce9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install dqx"
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eabeeecd-ce0a-4282-9900-5681be629f59",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restart Python"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25f796e6-6e12-4587-8c55-155373663dc3",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1758970662129}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Get bronze dataframe"
    }
   },
   "outputs": [],
   "source": [
    "raw_teams_df = spark.table('default.raw_teams')\n",
    "display(raw_teams_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b392ceb0-5910-4990-b89a-e051cbb088b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define base transfomations"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, explode, get, to_date, to_timestamp, concat_ws, lit\n",
    "\n",
    "def explode_arr(df: DataFrame) -> DataFrame:\n",
    "    return df.select(\n",
    "        col('competition'),\n",
    "        col('count'),\n",
    "        col('filters'),\n",
    "        col('season'),\n",
    "        explode('teams').alias('team')\n",
    "    )\n",
    "\n",
    "def flaten_structs(df: DataFrame) -> DataFrame:\n",
    "    return df.select(\n",
    "        col('competition.code').alias('competition_code'),\n",
    "        col('competition.emblem'),\n",
    "        col('competition.id').alias('competition_id'),\n",
    "        col('competition.name').alias('competition_name'),\n",
    "        col('competition.type'),\n",
    "        col('count'),\n",
    "        col('filters.season'),\n",
    "        col('season.currentMatchday'),\n",
    "        col('season.endDate'),\n",
    "        col('season.id').alias('season_id'),\n",
    "        col('season.startDate'),\n",
    "        col('season.winner'),\n",
    "        col('team.address'),\n",
    "        col('team.area.code').alias('code'),\n",
    "        col('team.area.flag'),\n",
    "        col('team.area.id').alias('area_id'),\n",
    "        col('team.area.name').alias('area_name'),\n",
    "        col('team.clubColors'),\n",
    "        col('team.coach.contract.start'),\n",
    "        col('team.coach.contract.until'),\n",
    "        col('team.coach.dateOfBirth'),\n",
    "        col('team.coach.id').alias('coach_id'),\n",
    "        col('team.coach.firstName'),\n",
    "        col('team.coach.lastName'),\n",
    "        col('team.coach.name').alias('coach_name'),\n",
    "        col('team.coach.nationality'),\n",
    "        col('team.crest'),\n",
    "        col('team.founded'),\n",
    "        col('team.id').alias('team_id'),\n",
    "        col('team.lastUpdated'),\n",
    "        col('team.name').alias('team_name'),\n",
    "        col('team.runningCompetitions'),\n",
    "        col('team.shortName'),\n",
    "        col('team.squad')\n",
    "    )\n",
    "\n",
    "def type_casting(df: DataFrame) -> DataFrame:\n",
    "    transformations = {}\n",
    "\n",
    "    month_cols = ['start', 'until']\n",
    "    for col_name in month_cols:\n",
    "        transformations[col_name] = to_date(concat_ws(\"-\", col(col_name), lit(\"01\")), \"yyyy-MM-dd\")\n",
    "\n",
    "    date_cols = ['startDate', 'endDate', 'dateOfBirth']\n",
    "    for col_name in date_cols:\n",
    "        transformations[col_name] = to_date(col(col_name), 'yyyy-MM-dd')\n",
    "\n",
    "    transformations['lastUpdated'] = to_timestamp(col('lastUpdated'), \"yyyy-MM-dd'T'HH:mm:ssX\")\n",
    "\n",
    "    return df.withColumns(transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a38a3bd-a13f-4a0f-a980-2000781e46d6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define cleaning transformations"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.labs.dqx import check_funcs\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.labs.dqx.rule import DQRowRule, DQDatasetRule, DQForEachColRule\n",
    "from databricks.labs.dqx.config import InputConfig, OutputConfig\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "def data_quality_checks(df: DataFrame) -> DataFrame:\n",
    "    dq_engine = DQEngine(WorkspaceClient())\n",
    "\n",
    "    checks = [\n",
    "        DQDatasetRule(\n",
    "            name='Check team_id uniqueness',\n",
    "            columns=['team_id'],\n",
    "            check_func=check_funcs.is_unique,\n",
    "            criticality='error',\n",
    "        ),\n",
    "        *DQForEachColRule(\n",
    "            name='Check that team_id & team_name are not null',\n",
    "            check_func=check_funcs.is_not_null_and_not_empty,\n",
    "            criticality='error',\n",
    "            columns=['team_id', 'team_name']\n",
    "        ).get_rules(),\n",
    "        *DQForEachColRule(\n",
    "            name='Check that date fields are not in future',\n",
    "            check_func=check_funcs.is_not_in_future,\n",
    "            criticality='error',\n",
    "            columns=['start', 'startDate', 'dateOfBirth', 'lastUpdated']\n",
    "        ).get_rules(),\n",
    "        DQRowRule(\n",
    "            name='Check if team_founded is in range',\n",
    "            check_func=check_funcs.is_in_range,\n",
    "            criticality='error',\n",
    "            column='founded',\n",
    "            check_func_kwargs={\"min_limit\": 1800, \"max_limit\": 2026}\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    valid_df, quarantined_df = dq_engine.apply_checks_and_split(df, checks)\n",
    "    return valid_df\n",
    "\n",
    "def select_fields(df: DataFrame) -> DataFrame:\n",
    "    return df.select(\n",
    "        col('team_id'),\n",
    "        col('team_name'),\n",
    "        col('shortName'),\n",
    "        col('address'),\n",
    "        col('clubColors'),\n",
    "        col('crest'),\n",
    "        col('founded'),\n",
    "        col('coach_id'),\n",
    "        col('coach_name'),\n",
    "        col('nationality'),\n",
    "        col('start'),\n",
    "        col('until'),\n",
    "        col('lastUpdated'),\n",
    "        col('runningCompetitions'),\n",
    "        col('squad')\n",
    "    )\n",
    "\n",
    "def normalize_col_names(df: DataFrame) -> DataFrame:\n",
    "    return df.withColumnsRenamed({\n",
    "        'shortName': 'team_short_name',\n",
    "        'clubColors': 'club_colors',\n",
    "        'nationality': 'coach_nationality',\n",
    "        'start': 'coach_contract_start',\n",
    "        'until': 'coach_contract_until',\n",
    "        'lastUpdated': 'last_updated',\n",
    "        'runningCompetitions': 'running_competitions'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efbeb52a-191b-47c2-bd3e-9503b444897f",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"crest\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1758973850023}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Apply transformations"
    }
   },
   "outputs": [],
   "source": [
    "stg_teams_df = (\n",
    "    raw_teams_df\n",
    "    .transform(explode_arr)\n",
    "    .transform(flaten_structs)\n",
    "    .transform(type_casting)\n",
    "    .transform(data_quality_checks)\n",
    "    .transform(select_fields)\n",
    "    .transform(normalize_col_names)\n",
    ")\n",
    "\n",
    "stg_teams_df.printSchema()\n",
    "display(stg_teams_df.limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5af6a15-7c4c-450d-bd03-6edc708e199b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Increpmental Upsert"
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "def incremental_upsert(dest_table: str, df: DataFrame, unique_key: str, updated_at: str, full_refresh=False):\n",
    "    if not spark.catalog.tableExists(dest_table) or full_refresh:\n",
    "        (\n",
    "            df\n",
    "            .write\n",
    "            .format('delta')\n",
    "            .mode('overwrite')\n",
    "            .option('overwriteSchema', 'true')\n",
    "            .saveAsTable(dest_table)\n",
    "        )\n",
    "    else:\n",
    "        last_max = (\n",
    "            spark.table(dest_table)\n",
    "                .agg(F.max(updated_at).alias('max_ts'))\n",
    "                .collect()[0]['max_ts']\n",
    "        )\n",
    "\n",
    "        incr_df = df.filter(F.col(updated_at) > last_max)\n",
    "\n",
    "        if not incr_df.isEmpty():\n",
    "            delta_table = DeltaTable.forName(spark, dest_table)\n",
    "            (\n",
    "                delta_table.alias('t')\n",
    "                    .merge(\n",
    "                        source=incr_df.alias('s'),\n",
    "                        condition=f's.{unique_key} = t.{unique_key}'\n",
    "                    )\n",
    "                    .whenMatchedUpdateAll()\n",
    "                    .whenNotMatchedInsertAll()\n",
    "                    .execute()\n",
    "            )\n",
    "\n",
    "dest_table = 'default.stg_teams'\n",
    "incremental_upsert(dest_table, stg_teams_df, 'team_id', 'last_updated')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_teams",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
